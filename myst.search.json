{"version":"1","records":[{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR"},"type":"lvl1","url":"/prr-stac-introduction","position":0},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR"},"content":"","type":"content","url":"/prr-stac-introduction","position":1},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"Introduction"},"type":"lvl3","url":"/prr-stac-introduction#introduction","position":2},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"Introduction"},"content":"\n\nThis notebook has been created to show the core steps required of EarthCODE users to upload their research outcomes to the \n\nESA Project Results Repository (PRR). It focuses on generating metadata for a project with a single  netcdf file.\n\nPRR provides access to data, workflows, experiments and documentation from ESA Projects organised across Collections, accessible via the \n\nSTAC API. Each Collection contains \n\nSTAC Items, with their related Assets stored within the PRR storage. Scientists/commercial companies can access the PRR via the \n\nEarthCODE and \n\nAPEx projects.\n\nThe \n\nSTAC Specification, provides detailed explanation and more information on this metadata format.\n\nIn order to upload data to the ESA Project Results Repository (PRR) you have to generate a STAC Collection that is associated to your files. The STAC Collection provides metadata about your files and makes them searchable and machine readable. The metadata generation process is organised in four steps process:\n\nGenerate a root STAC Collection\n\nGroup your dataset files into STAC Items and STAC Assets\n\nAdd the Items to the Collection\n\nSave the normalised Collection\n\nThe easiest way to generate all the required files is to use a STAC library, such as pystac or riostac. This library will take care of creating the links and formating the files in the correct way.  In the examples below we are using pystac.\n\nHave a look at the steps below and learn how to prepare your dataset to generate a valid STAC Collection. You will find all the steps descibed in the markdown cell, together with the example code (executable) to make this process easier. Please adjust the information in the fields required to describe your Collection and Items according to the comments, starting with : ‚Äú#‚Äù\n\nNOTE: Depending on the information that you put in the Assets or Items the code, you may get an error about an object not being json-serialisable. If this happens, you have to transform the problem field into an object that can be described using standard JSON. For example, transforming a numpy array into a list.\n\n","type":"content","url":"/prr-stac-introduction#introduction","position":3},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"üåä Example: 4DATLANTIC-OHC Project"},"type":"lvl3","url":"/prr-stac-introduction#id-example-4datlantic-ohc-project","position":4},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"üåä Example: 4DATLANTIC-OHC Project"},"content":"The code below demonstrates how to perform the necessary steps using real data from the ESA Regional Initiative Project 4DATLANTIC-OHC. The project focuses on ocean heat content and provides monthly gridded Atlantic Ocean heat content change as well as OHC trends and their uncertainties.\n\nüîó Learn more about the project here: \n\n4DATLANTIC-OHC ‚Äì EO4Society \nüîó Check the project website: \n\n4DATLANTIC-OHC ‚Äì Website","type":"content","url":"/prr-stac-introduction#id-example-4datlantic-ohc-project","position":5},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl4":"Acknowledgment","lvl3":"üåä Example: 4DATLANTIC-OHC Project"},"type":"lvl4","url":"/prr-stac-introduction#acknowledgment","position":6},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl4":"Acknowledgment","lvl3":"üåä Example: 4DATLANTIC-OHC Project"},"content":"We gratefully acknowledge the 4DATLANTIC-OHC project team for providing access to the data used in this example.\n\nThis example is intended to help you understand the workflow and apply similar steps to your own Earth observation data analysis. \n\n","type":"content","url":"/prr-stac-introduction#acknowledgment","position":7},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"Import necessary Python libraries"},"type":"lvl3","url":"/prr-stac-introduction#import-necessary-python-libraries","position":8},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"Import necessary Python libraries"},"content":"You can create an example conda/miniconda enviroment to run the below code using:conda create -n prr_stack_example pystac xarray shapely\nconda activate prr_stack_example\n\n# import libraries\nfrom pystac import Collection\nimport pystac\nimport xarray as xr\nimport shapely\nimport json\nfrom datetime import datetime\n\n","type":"content","url":"/prr-stac-introduction#import-necessary-python-libraries","position":9},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"1. Generate a root STAC collection"},"type":"lvl3","url":"/prr-stac-introduction#id-1-generate-a-root-stac-collection","position":10},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"1. Generate a root STAC collection"},"content":"The root STAC Collection provides a general description of the enitre dataset, that you would like to store in ESA PRR. In the STAC Specification a Collection is defined as  an extension of the STAC Catalog with additional information such as the extents, license, keywords, providers, etc that describe STAC Items that fall within the Collection. \n\nIn short: it behaves as the container to store the various Items that build up your dataset. \n\nSTAC Collection has some required fields that you need to provide in order to build its valid description. Most of these metadata fields should be extracted from your data.\nPlease have a look at the example below.{\n  \"type\": \"Collection\", # Do not change\n  \"id\": \"\", # add a unique variation of project name + dataset name \n  \"stac_version\": \"1.1.0\", # Do not change\n  \"title\": \"\", # Meaningful title of your dataset\n  \"description\": \"\", # General description of your dataset\n  \"extent\": {\n    \"spatial\": {\n      \"bbox\": [\n        [\n          -180.0,\n          -90.0,\n          180.0,\n          90.0\n        ]\n      ]\n    }, # Spatial extent of your dataset. If you have multiple data files take the minimum bounding box that covers all.\n    \"temporal\": {\n      \"interval\": [\n        [\n          \"1982-01-01T00:00:00Z\",\n          \"2022-12-31T23:59:59Z\"\n        ] # Temporal extent of your dataset. If you have multiple data files take the minimum temporal range that covers all.\n      ]\n    }\n  },\n\"license\": \"\", # the license that applies to entire dataset\n\"links\": [] # do not change\n\n}\n\n","type":"content","url":"/prr-stac-introduction#id-1-generate-a-root-stac-collection","position":11},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Create Collection","lvl3":"1. Generate a root STAC collection"},"type":"lvl5","url":"/prr-stac-introduction#example-create-collection","position":12},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Create Collection","lvl3":"1. Generate a root STAC collection"},"content":"\n\n# define collection id, since it will be reused\ncollectionid = \"4datlantic-ohc\"\n\n# create the root collection using pystac.Collection\n\ncollection = Collection.from_dict(\n    \n{\n  \"type\": \"Collection\",\n  \"id\": collectionid,\n  \"stac_version\": \"1.1.0\",\n  \"title\": \"Atlantic Ocean heat content change\",\n  \"description\": \"Given the major role of the Atlantic Ocean in the climate system, it is essential to characterize the temporal and spatial variations of its heat content. The OHC product results from the space geodetic approach also called altimetry-gravimetry approach. This dataset contains variables as 3D grids of ocean heat content anomalies at 1x1 resolution and monthly time step. Error variance-covariance matrices of OHC at regional scale and annual resolution are also provided. See Experimental Dataset Description for details: https://www.aviso.altimetry.fr/fileadmin/documents/data/tools/OHC-EEI/OHCATL-DT-035-MAG_EDD_V2.0.pdf.Version. V2-0 of Dataset published 2022 in Centre National d‚ÄôEtudes Spatiales. This dataset has been produced within the framework of the 4DAtlantic-Ocean heat content Project funded by ESA.\",\n  \"extent\": {\n    \"spatial\": {\n      \"bbox\": [\n        [-100, \n         -90, \n         25,\n         90]\n      ]\n    },\n    \"temporal\": {\n      \"interval\": [\n        [\n          \"2002-04-15T18:07:12Z\",\n          \"2023-09-01T18:59:59Z\"\n        ]\n      ]\n    }\n  },\n  \"license\": \"Aviso License\",\n  \"links\": []\n\n}\n\n)\n\ncollection\n\n","type":"content","url":"/prr-stac-introduction#example-create-collection","position":13},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"type":"lvl3","url":"/prr-stac-introduction#id-2-group-your-dataset-files-into-stac-items-and-stac-assets","position":14},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"content":"The second step is to describe the different files as Items and Assets. This is the most time-consuming step. There are multiple strategies for doing this and it is up to you to decide how to do it. The main consideration should be usability of the data.\n\nFor example:\n\nMicrosoft Planatery Computer groups its Sentinel-2 data into Items which represent individual regions, and each Item has 13 Assets each representing a band - \n\nhttps://‚Äãstacindex‚Äã.org‚Äã/catalogs‚Äã/microsoft‚Äã-pc‚Äã#‚Äã/43bjKKcJQfxYaT1ir3Ep6uENfjEoQrjkzhd2‚Äã?cp‚Äã=‚Äã1‚Äã&‚Äãt‚Äã=5 .\n\nThe California Forest Observatory (on Google Earth Engine) groups its data into Items, where each Item represents a specific year, data type and resolution for the whole study area. Each Item has only one Asset ( dataset ) associated with it - \n\nhttps://‚Äãstacindex‚Äã.org‚Äã/catalogs‚Äã/forest‚Äã-observatory‚Äã#‚Äã/4dGsSbK8F5jjmhRZYE6kjUMmgWCUKe6J2qqw‚Äã?t‚Äã=2.\n\nA More complex example from real-data from ESA-funded project: \n\nESA Projects Results Repository, gives the researchers flexibility in terms on how their datasets will be grouped into Items and Assets. You may need to consider that the more Items you have in your Collection, the slower the browsing would be if the user would like to browse through the publicly open STAC Browser. Please have a look at one example, that provides one Sentinel-3 AMPLI Ice Sheet Elevation Collection with around 400 Items complemented by around 360 Assets each.\n\n\nhttps://‚Äãeoresults‚Äã.esa‚Äã.int‚Äã/browser‚Äã/‚Äã#‚Äã/external‚Äã/eoresults‚Äã.esa‚Äã.int‚Äã/stac‚Äã/collections‚Äã/sentinel3‚Äã-ampli‚Äã-ice‚Äã-sheet‚Äã-elevation\n\nMore general examples about creating STAC catalogs are available here - \n\nhttps://‚Äãgithub‚Äã.com‚Äã/stac‚Äã-utils‚Äã/pystac‚Äã/tree‚Äã/main‚Äã/docs‚Äã/tutorials.\n\nThe easiest way to generate the required STAC Items is to copy over the metadata directly from your files.\n\n","type":"content","url":"/prr-stac-introduction#id-2-group-your-dataset-files-into-stac-items-and-stac-assets","position":15},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Open Dataset","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"type":"lvl5","url":"/prr-stac-introduction#example-open-dataset","position":16},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Open Dataset","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"content":"\n\nimport urllib.request\n\n# Download the dataset locally\nurllib.request.urlretrieve('https://data.aviso.altimetry.fr/aviso-gateway/data/indicators/OHC_EEI/4DAtlantic_OHC/OHC_4DATLANTIC_200204_202212_V2-0.nc', 'OHC_4DATLANTIC_200204_202212_V2-0.nc')\n\n\n# open dataset\n\n# define relative filepath within the folder structure you want to upload to the PRRs\nfilepath = 'OHC_4DATLANTIC_200204_202212_V2-0.nc'\n\nds = xr.open_dataset(filepath)\nds\n\n# helper function to convert numpy arrays to lists\nimport numpy as np\ndef convert_to_json_serialisable(attrs):\n    attrs = attrs.copy()\n    for attr in attrs.keys():\n        if isinstance(attrs[attr], np.ndarray):\n            attrs[attr] = attrs[attr].tolist()\n    return attrs\n\n","type":"content","url":"/prr-stac-introduction#example-open-dataset","position":17},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Create valid STAC Item from your product (nc)","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"type":"lvl5","url":"/prr-stac-introduction#example-create-valid-stac-item-from-your-product-nc","position":18},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Create valid STAC Item from your product (nc)","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"content":"\n\n# Describe the first file (Item)\n\n\n# 1. extract the spatial extent from the .nc file \nbbox = [ds['longitude'].values.min(), ds['latitude'].values.min(), ds['longitude'].values.max(), ds['latitude'].values.max(), ]\ngeometry = json.loads(json.dumps(shapely.box(*bbox).__geo_interface__))\n\n# 2. extract additional information (properties) from the .nc file and create the STAC Item\nitem = pystac.Item(\n    id=collectionid + 'v2',\n    geometry=geometry,\n    datetime=datetime.strptime('2025-02-05', '%Y-%m-%d'),\n    bbox=bbox,\n    properties= {\n        \"history\": ds.attrs['history'],\n        \"source\": ds.attrs['source'],\n        \"comment\": ds.attrs['comment'],\n        \"references\": ds.attrs['references'],\n        \"summary\": ds.attrs['summary'],\n        \"version\": ds.attrs['version'],\n        \"conventions\": ds.attrs['Conventions'],\n    } # please note that this field is not mandatory by STAC specification, \n        # and depends on the information you have provided within your original dataset.\n      # You are encouraged to provide as complete information as possible here, to make sure your product has rich metadata, facilitating product discoverability and usability\n)\n\n# 3. Extract variable properties at the Item level, since there is only one file\nstac_property_prefix = 'variable_'\nitem.properties[f\"{stac_property_prefix}ohc\"] = convert_to_json_serialisable(ds.variables['ohc'].attrs)\nitem.properties[f\"{stac_property_prefix}ohc_var_covar_matrix_local\"] = convert_to_json_serialisable(ds.variables['ohc_var_covar_matrix_local'].attrs)\nitem.properties[f\"{stac_property_prefix}ohc_mask\"] = convert_to_json_serialisable(ds.variables['ohc_mask'].attrs)\n\n\n# 4. Add asset\nitem.add_asset(\n            key='OHC Atlantic Dataset', # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/{filepath}', # keep the /d/ reference\n                media_type=\"application/x-netcdf\",\n                roles=[\"data\"],\n            )\n) ## Please note that asset can describe a satllite image band, as well as single nc or tiff file, depending on the orginal data structure. \n\nitem # Preview created Item\n\n","type":"content","url":"/prr-stac-introduction#example-create-valid-stac-item-from-your-product-nc","position":19},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl2":"3. Add the STAC Item to the STAC Collection"},"type":"lvl2","url":"/prr-stac-introduction#id-3-add-the-stac-item-to-the-stac-collection","position":20},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl2":"3. Add the STAC Item to the STAC Collection"},"content":"Adding the Items to the Collection is a single function call when using a library such as pystac.\n\ncollection.add_item(item)\n\n","type":"content","url":"/prr-stac-introduction#id-3-add-the-stac-item-to-the-stac-collection","position":21},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl2":"4. Save the Collection"},"type":"lvl2","url":"/prr-stac-introduction#id-4-save-the-collection","position":22},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl2":"4. Save the Collection"},"content":"Again this step is a single function call.\n\ncollection.normalize_and_save(\n    root_href='example_4datlantic/', # path to the self-contained folder with STAC Collection\n    catalog_type=pystac.CatalogType.SELF_CONTAINED\n)\n\ncollection\n\n","type":"content","url":"/prr-stac-introduction#id-4-save-the-collection","position":23},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Congratulations, you have created your first STAC Collection. ","lvl2":"4. Save the Collection"},"type":"lvl5","url":"/prr-stac-introduction#congratulations-you-have-created-your-first-stac-collection","position":24},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Congratulations, you have created your first STAC Collection. ","lvl2":"4. Save the Collection"},"content":"Now, you have your results ready to be ingested into ESA PRR. To request data storage in ESA PRR, contact EarthCODE team at: \n\nearth-code@esa.int and provide following information:\n\nyour project name\n\ntotal size of your dataset\n\nlink to STAC Collection created together with associated Items (e.g. entire example_4datlantic folder) - can be provided as a .zip or link to online repository / GitHub public repository\n\nlink to the datasets (access link to final outcomes of the project or assets)\n\nspecify any restrictions related to the access of your dataset.\n\nin the email, do not forget to CC your ESA TO to acknowledge that the dataset will be imported into PRR.\n\nOnce the email is received, the EarthCODE team will make a request to publish your product into PRR on your behalf (in the future the self-ingestion system will be supported).\n\nOnce the collection is imported you will receive a dedicated URL to your products, which you can use to create the record on Open Science Data Catalogue to make your data discoverable or/and request a DOI for your dataset (at the moment this has to be done by external service of your choice).","type":"content","url":"/prr-stac-introduction#congratulations-you-have-created-your-first-stac-collection","position":25},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog"},"type":"lvl1","url":"/creating-an-item-catalog","position":0},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog"},"content":"","type":"content","url":"/creating-an-item-catalog","position":1},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Context"},"type":"lvl3","url":"/creating-an-item-catalog#context","position":2},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Context"},"content":"","type":"content","url":"/creating-an-item-catalog#context","position":3},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Purpose","lvl3":"Context"},"type":"lvl4","url":"/creating-an-item-catalog#purpose","position":4},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Purpose","lvl3":"Context"},"content":"The purpose of this tutorial is to learn how to share research outcomes with the wider research community in Open Science Catalog. This can be done by creating STAC Catalogs that\ndescribe a specific dataset you are willing to share.\n\nThis tutorial provides steps necessary to Create STAC Item Catalog in an semi-automated way, using the PySTAC library. By following these steps you will be able to create a self-contained STAC Catalog with individual items in a JSON format. This catalog should be hosted in your own (or institutional) public GitHub repository to ensure it is accessible. (See more on the requirements about this Catalog in the \n\ndocumentation).\n\nIn this example we will upload it to an open-access repository on GitHub. In the next tutorial we will create the actual Open Science Catalog entry, where we will create a full metadata description of our dataset with a link to this Item Catalog.","type":"content","url":"/creating-an-item-catalog#purpose","position":5},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl5":"STAC Items","lvl4":"Purpose","lvl3":"Context"},"type":"lvl5","url":"/creating-an-item-catalog#stac-items","position":6},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl5":"STAC Items","lvl4":"Purpose","lvl3":"Context"},"content":"A STAC Item is the lowest level component of a STAC catalog. All STAC Items must have an associated data Asset, in addition to the Asset (which you can think of as a data file), the Item also contains metadata about the data itself, such as:\n\nSpatioTemporal extent including start and end time and geographical extent (coordinates)\n\nVariables\n\nFile type\n\nFile size\n\nImportant\n\nThink about the persistence of your data!\nIf your data files are not currently stored in an open-access and persistent storage, you can \n\ncontact the ESA team who will assist you to upload your data to the ESA Project Results Repository (PRR). The same applies for the repository we will upload our STAC Item Catalog to!","type":"content","url":"/creating-an-item-catalog#stac-items","position":7},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Prerequisites","lvl3":"Context"},"type":"lvl4","url":"/creating-an-item-catalog#prerequisites","position":8},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Prerequisites","lvl3":"Context"},"content":"In this example we assume that the data files are already uploaded to a remote storage, and we have access to the download URLs, but feel free to modify this example for your own data files!\n\nWe will be using this supraglacial lakes dataset: \n\nhttps://‚Äãzenodo‚Äã.org‚Äã/records‚Äã/7568049‚Äã#‚Äã.ZDbG4nbP1aQ. We have also noted down the download links for 5 of the assets:https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20171111T205337_20171111T205438_008239_00E91A_F8D1.tif\nhttps://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20190224T203744_20190224T203844_015093_01C356_B9C1.tif\nhttps://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20170620T205332_20170620T205433_006139_00AC89_6857.tif\nhttps://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20180923T202118_20180923T202218_012847_017B82_7DD5.tif\nhttps://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20181108T203747_20181108T203847_013518_01903B_D463.tif\n\nThis notebook uses Python 3.10.11\n\nTip\n\nYou can reuse this example with your own data links, as long as they point to an open access, persistent and remote storage!\n\n","type":"content","url":"/creating-an-item-catalog#prerequisites","position":9},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Loading Libraries"},"type":"lvl3","url":"/creating-an-item-catalog#loading-libraries","position":10},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Loading Libraries"},"content":"Make sure you have installed the requirements, e.g. with pip install pystac rasterio\n\nimport json\nimport time\nimport requests\n\nimport pystac\nimport rasterio\nfrom pathlib import Path\n\n","type":"content","url":"/creating-an-item-catalog#loading-libraries","position":11},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl2":"Creating the Item Catalog"},"type":"lvl2","url":"/creating-an-item-catalog#creating-the-item-catalog","position":12},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl2":"Creating the Item Catalog"},"content":"To correctly reference our Items, they need to be linked in the STAC Catalog. This catalog should also include the following minimum information:\n\nTitle of the Catalog\n\nDescription\n\nID (e.g. catalog-id: can be short name of the dataset)\n\ntitle = \"Item Catalog Example\"\ndescription = \"A collection of supraglacial lakes data in a very useful example notebook.\"\ncatalog_id = \"supraglacial-lakes-example-2025\"\n\ncatalog = pystac.Catalog(\n    id=catalog_id,\n    title=title,\n    description=description,\n)\n\ncatalog\n\nThat‚Äôs all! Most of the metadata will be added to the Items which we will add to this catalog shortly.\n\n","type":"content","url":"/creating-an-item-catalog#creating-the-item-catalog","position":13},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Creating a single STAC Item","lvl2":"Creating the Item Catalog"},"type":"lvl3","url":"/creating-an-item-catalog#creating-a-single-stac-item","position":14},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Creating a single STAC Item","lvl2":"Creating the Item Catalog"},"content":"Manually creating STAC Items can be cumbersome and is prone to errors (but possible!). Luckily there are many tools that can make the process a lot easier.\n\nHere we will use rio_stac \n\n(documentation here) which is a library that we can use to open and extract metadata from raster datasets.\n\nfilenames = [\n    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20171111T205337_20171111T205438_008239_00E91A_F8D1.tif\",\n    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20190224T203744_20190224T203844_015093_01C356_B9C1.tif\",\n    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20170620T205332_20170620T205433_006139_00AC89_6857.tif\",\n    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20180923T202118_20180923T202218_012847_017B82_7DD5.tif\",\n    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20181108T203747_20181108T203847_013518_01903B_D463.tif\",\n]\n\nfrom rio_stac import create_stac_item\n\nitem = create_stac_item(\n    source=filenames[0],\n    id=\"item_1\",\n    asset_name=\"data\",  # EarthCODE standard asset name\n    # all the metadata!\n    with_eo=True,\n    with_proj=True,\n    with_raster=True,\n)\n\nInspecting the result we can see that this function has extracted rich information about our raster file. This information is attached to the Item. This Item also has an \"assets\" attribute which references the actual data.\n\nImportant: Verify that your references always point to the remote open storage!\n\nitem\n\n","type":"content","url":"/creating-an-item-catalog#creating-a-single-stac-item","position":15},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Creating the rest of our Items","lvl2":"Creating the Item Catalog"},"type":"lvl3","url":"/creating-an-item-catalog#creating-the-rest-of-our-items","position":16},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Creating the rest of our Items","lvl2":"Creating the Item Catalog"},"content":"Now that we have shown how to generate a single Item using rio_stac, we can repeat the process for the rest of our data files. The goal is to create a list of STAC Items, that we can add to our Catalog with the buit-in Catalog.add_items() method.\n\nWe could in principle just iterate over the method above, but in order to respect the rate limits for our data provider (Zenodo), we define a function which reads the response headers and responds appropriately.\n\nThis function also saves the file to a local temporary destination instead of reading the data from Zenodo directly.\n\nimport time\nimport requests\n\ndef download_zenodo_file(url: str, local_path: str, max_retries: int = 5) -> None:\n    \"\"\"\n    Download a file from Zenodo into local_path, respecting rate limits if we hit 429 responses.\n    \n    :param url: The direct download URL from Zenodo.\n    :param local_path: Where to save the file locally.\n    :param max_retries: Number of times to retry the download if repeatedly rate-limited.\n    \"\"\"\n    attempt = 0\n    \n    while attempt < max_retries:\n        response = requests.get(url, stream=True)\n        \n        if response.status_code == 200:\n            with open(local_path, 'wb') as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    f.write(chunk)\n            return \n        \n        # If rate-limited (HTTP 429), then check rate-limit headers and wait.\n        elif response.status_code == 429:\n            attempt += 1\n            if reset_timestamp := response.headers.get(\"X-RateLimit-Reset\") is not None:\n                now = time.time()\n                wait_seconds = int(reset_timestamp) - int(now)\n                wait_seconds = max(wait_seconds, 1)  # Wait at least 1 second.\n                print(f\"Got 429 Too Many Requests. Waiting ~{wait_seconds} seconds.\")\n                time.sleep(wait_seconds)\n        else:\n            response.raise_for_status()\n    \n    raise RuntimeError(f\"Failed to download {url} after {max_retries} retries.\")\n\nNow we can iterate over the rest of our data files and create the STAC items.\n\nimport rasterio\n\nitems = []\nlocal_tmp_file = \"tmp.tif\"\n\nfor idx, remote_url in enumerate(filenames[0:]):\n    # Save our dataset to the temporary file\n    download_zenodo_file(remote_url, local_tmp_file)\n\n    # Inspect the local file and create a STAC Item\n    item = create_stac_item(\n        source=local_tmp_file,\n        id=f\"item_{idx+1}\",\n        asset_name=\"data\",\n        asset_href=remote_url,  # Explicitly set the asset reference to the remote one!\n        with_eo=True,\n        with_proj=True,\n        with_raster=True,\n    )\n\n    items.append(item)\n\n# Verify that our items all point to the correct reference\nfor item in items:\n    print(item.assets['data'].href)\n\nLooks good!\n\n","type":"content","url":"/creating-an-item-catalog#creating-the-rest-of-our-items","position":17},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Adding Items to our Item Catalog","lvl2":"Creating the Item Catalog"},"type":"lvl3","url":"/creating-an-item-catalog#adding-items-to-our-item-catalog","position":18},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Adding Items to our Item Catalog","lvl2":"Creating the Item Catalog"},"content":"Now that we have defined our items, we can add them to our catalog.\n\ncatalog.add_items(items)\n\ncatalog\n\n","type":"content","url":"/creating-an-item-catalog#adding-items-to-our-item-catalog","position":19},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Saving the Catalog","lvl2":"Creating the Item Catalog"},"type":"lvl3","url":"/creating-an-item-catalog#saving-the-catalog","position":20},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Saving the Catalog","lvl2":"Creating the Item Catalog"},"content":"If we inspect the Catalog, we can see that it now contains Links to the Items, but the links themselves don‚Äôt contain any references.\n\nWith PySTAC, the real magic happens when you normalize and save the Catalog. This is when all the links are resolved, and a folder structure will be laid out following best practices, automatically!\n\nWhat we will do is to specify a target location, which will become the root folder of our Catalog. When we normalize the Catalog to this folder, all the internal references will be resolved with relative paths. When we save the Catalog, PySTAC will generate the JSON files in the folder we just normalized to.\n\nWe normalize and save the Catalog as ‚Äúself contained‚Äù. Here is the description of a self-contained catalog from the \n\nPySTAC API documentation:\n\n‚ÄúA ‚Äòself-contained catalog‚Äô is one that is designed for portability. Users may want to download an online catalog from and be able to use it on their local computer, so all links need to be relative.‚Äù\n\nIn other words, exactly what we want to make our data accessible!\n\noutput_folder = \"supraglacial-lakes-item-catalog\"\n\ncatalog.normalize_and_save(root_href=output_folder, catalog_type=pystac.CatalogType.SELF_CONTAINED)\n\nIf you inspect the Catalog you can see that PySTAC has added a few more links to our Catalog, namely to the root catalog and itself, which in this istance is the same.\n\nAlso notice that the Link.href attributes show absolute paths in the notebook. However, you should now have the actual STAC catalog saved in the output_folder.\n\nThe folder will have the following structure:supraglacial-lakes-item-catalog\n‚îú‚îÄ‚îÄ catalog.json\n‚îú‚îÄ‚îÄ item_1\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ item_1.json\n‚îú‚îÄ‚îÄ item_2\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ item_2.json\n‚îú‚îÄ‚îÄ item_3\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ item_3.json\n‚îú‚îÄ‚îÄ item_4\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ item_4.json\n‚îî‚îÄ‚îÄ item_5\n    ‚îî‚îÄ‚îÄ item_5.json\n\nLooking at the catalog.json:{\n  \"type\": \"Catalog\",\n  \"id\": \"supraglacial-lakes-example-2025\",\n  \"stac_version\": \"1.1.0\",\n  \"description\": \"A collection of supraglacial lakes data in a very useful example notebook.\",\n  \"links\": [\n    {\n      \"rel\": \"root\",\n      \"href\": \"./catalog.json\",\n      \"type\": \"application/json\",\n      \"title\": \"Item Catalog Example\"\n    },\n    {\n      \"rel\": \"item\",\n      \"href\": \"./item_1/item_1.json\",\n      \"type\": \"application/geo+json\"\n    },\n    {\n      \"rel\": \"item\",\n      \"href\": \"./item_2/item_2.json\",\n      \"type\": \"application/geo+json\"\n    },\n    {\n      \"rel\": \"item\",\n      \"href\": \"./item_3/item_3.json\",\n      \"type\": \"application/geo+json\"\n    },\n    {\n      \"rel\": \"item\",\n      \"href\": \"./item_4/item_4.json\",\n      \"type\": \"application/geo+json\"\n    },\n    {\n      \"rel\": \"item\",\n      \"href\": \"./item_5/item_5.json\",\n      \"type\": \"application/geo+json\"\n    }\n  ],\n  \"title\": \"Item Catalog Example\"\n}\n\nwe can verify that everything looks correct.\n\nThe item JSON files should have the following links:  \"links\": [\n    {\n      \"rel\": \"root\",\n      \"href\": \"../catalog.json\",\n      \"type\": \"application/json\",\n      \"title\": \"Item Catalog Example\"\n    },\n    {\n      \"rel\": \"parent\",\n      \"href\": \"../catalog.json\",\n      \"type\": \"application/json\",\n      \"title\": \"Item Catalog Example\"\n    }\n  ],\n\n... among all the other metadata we have added.\n\nThat's it! We have now created a self-contained STAC Item Catalog that contains all the metadata of our data, in compliance with the EarthCODE specifications for FAIR and open science. Now we just need to upload it to somewhere people can access it.\n\n","type":"content","url":"/creating-an-item-catalog#saving-the-catalog","position":21},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Upload the Item Catalog","lvl2":"Creating the Item Catalog"},"type":"lvl3","url":"/creating-an-item-catalog#upload-the-item-catalog","position":22},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Upload the Item Catalog","lvl2":"Creating the Item Catalog"},"content":"In this part we will upload the Catalog in order to make it available. Feel free to do this in any way you like as long as you are sure the files will remain accessible!\n\nA good option is to upload the files we just created to GitHub. In the next part of the tutorial, when we will create an entry to the Open Science Catalog, we will only need the URL for the catalog.json we have in our root. The STAC browser will read the files directly from this repository and extract all the information from our Items automatically.\n\nWe will now show how this can be done with GitHub and the git CLI.\n\n","type":"content","url":"/creating-an-item-catalog#upload-the-item-catalog","position":23},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Create a public GitHub repository","lvl3":"Upload the Item Catalog","lvl2":"Creating the Item Catalog"},"type":"lvl4","url":"/creating-an-item-catalog#create-a-public-github-repository","position":24},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Create a public GitHub repository","lvl3":"Upload the Item Catalog","lvl2":"Creating the Item Catalog"},"content":"Go to \n\ngithub.com/new and create a remote repository. Here we will name it the same as our local folder, make sure it is set to public, and ignore everything else.\n\n\n\nGitHub create a new repository\n\nAfter creating the repository, you can simply click upload existing files to upload your files manually, or if you are comfortable with git, do it through the command line interface:# Navigate to the Item Catalog we want to upload\ncd supraglacial-lakes-item-catalog\n\n# Initialise it as a git repository\ngit init\n\n# Add the URL to your newly created GitHub repository as the remote version of your local files\ngit remote add origin https://github.com/<username>/supraglacial-lakes-item-catalog.git\n\n# Add and commit your files\ngit add --all\ngit commit -m \"Useful commit message\"\n\n# Set the remote main as the upstream version of your local main, and push your changes\ngit push --set-upstream origin main\n\nWhen you refresh GitHub page, you should see your STAC catalog.\n\n\n\nNew GitHub repository\n\nThat‚Äôs it!\n\nIn the next stages we will explain how to create and add your product to the Open Science Catalog, linking to the Items we just created.","type":"content","url":"/creating-an-item-catalog#create-a-public-github-repository","position":25},{"hierarchy":{"lvl1":"DeepCode"},"type":"lvl1","url":"/deepcode-example","position":0},{"hierarchy":{"lvl1":"DeepCode"},"content":"A tutorial on how to use DeepCode to upload data to the Open Science Catalog.","type":"content","url":"/deepcode-example","position":1},{"hierarchy":{"lvl1":"Git Clerk"},"type":"lvl1","url":"/git-clerk-example","position":0},{"hierarchy":{"lvl1":"Git Clerk"},"content":"A tutorial on how to use the Git Clerk to upload data to the Open Science Catalog.","type":"content","url":"/git-clerk-example","position":1},{"hierarchy":{"lvl1":"Open Science Catalog"},"type":"lvl1","url":"/index-1","position":0},{"hierarchy":{"lvl1":"Open Science Catalog"},"content":"","type":"content","url":"/index-1","position":1},{"hierarchy":{"lvl1":"Open Science Catalog","lvl2":"Uploading data to the Open Science Catalog"},"type":"lvl2","url":"/index-1#uploading-data-to-the-open-science-catalog","position":2},{"hierarchy":{"lvl1":"Open Science Catalog","lvl2":"Uploading data to the Open Science Catalog"},"content":"Here you can find guides and example notebooks on how to use the Open Science Catalog.","type":"content","url":"/index-1#uploading-data-to-the-open-science-catalog","position":3},{"hierarchy":{"lvl1":"Open Science Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"type":"lvl3","url":"/index-1#uploading-data","position":4},{"hierarchy":{"lvl1":"Open Science Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"content":"If you are looking to upload your data please refer to the following guides. Choose the method that best suits your use case!","type":"content","url":"/index-1#uploading-data","position":5},{"hierarchy":{"lvl1":"Open Science Catalog","lvl4":"1: Creating and Uploading an Item Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"type":"lvl4","url":"/index-1#id-1-creating-and-uploading-an-item-catalog","position":6},{"hierarchy":{"lvl1":"Open Science Catalog","lvl4":"1: Creating and Uploading an Item Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"content":"Creating an Item Catalog - A notebook explaining how Item Catalogs should be created, uses raster data.","type":"content","url":"/index-1#id-1-creating-and-uploading-an-item-catalog","position":7},{"hierarchy":{"lvl1":"Open Science Catalog","lvl4":"2: Adding a Product entry to the Open Science Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"type":"lvl4","url":"/index-1#id-2-adding-a-product-entry-to-the-open-science-catalog","position":8},{"hierarchy":{"lvl1":"Open Science Catalog","lvl4":"2: Adding a Product entry to the Open Science Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"content":"PySTAC notebook - A guide for manually creating Product entries using PySTAC. Requires some knowledge of git.\n\nGit Clerk - A guide for using the Git Clerk tool which is a user interface for automatically creating product entries and creating a Pull Request in the OSC GitHub Repo.\n\nDeepCode - An example using DeepCode: a library for automatically generating product entries for DeepESDL datasets.","type":"content","url":"/index-1#id-2-adding-a-product-entry-to-the-open-science-catalog","position":9},{"hierarchy":{"lvl1":"Manual Example (PySTAC)"},"type":"lvl1","url":"/manual-example","position":0},{"hierarchy":{"lvl1":"Manual Example (PySTAC)"},"content":"A tutorial on how to manually (and painstakingly) add a product to the OSC.","type":"content","url":"/manual-example","position":1},{"hierarchy":{"lvl1":"Stactools Full Example"},"type":"lvl1","url":"/stactools-old-example","position":0},{"hierarchy":{"lvl1":"Stactools Full Example"},"content":"","type":"content","url":"/stactools-old-example","position":1},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"System requirements"},"type":"lvl2","url":"/stactools-old-example#system-requirements","position":2},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"System requirements"},"content":"Ubuntu OS min version > 20. Script tested on Ubuntu 22.04 and Ubuntu 20.04 version.\n\nMinimum requirements: 2 GB RAM, 2 CPUs, 32 GB of disk space.\n\nUser with full sudo privileges to run all Linux commands and install packages as root.\n\nSelection of packages to be installed in order to run bash script: python 3 , gdal , tree, jq, parallel , curl, stactools.\n\nPython 3.8 or greater\n\nFollowing dependencies are necessary to make correct conversion of products to be published: stactools - to manage STAC catalogs\nstactools-datacube - to enrich STAC items with datacube metadata\nPlease find full documentation and installation instructions here: \n\nhttps://‚Äãstactools‚Äã.readthedocs‚Äã.io‚Äã/en‚Äã/stable‚Äã/index‚Äã.html","type":"content","url":"/stactools-old-example#system-requirements","position":3},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add metadata of a single product (item) to the catalogue"},"type":"lvl2","url":"/stactools-old-example#add-metadata-of-a-single-product-item-to-the-catalogue","position":4},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add metadata of a single product (item) to the catalogue"},"content":"Manual ingestion of single item into catalogue is rather simple and straightforward when you have all metadata prepared correctly and when you follow these few steps on how to add new product (collection.json) to a publicly open repository of Open Science Data Catalogue.\n\nPlease note that this workflow is applicable also to other elements of the catalogue such as Projects, Themes, Variables, EO Missions.\nHere the procedure of adding or updating metadata of single item using GitHub on Web browser is provided.\n\nGo to open-science-catalog-metadata-staging repository:\n\n\nhttps://‚Äãgithub‚Äã.com‚Äã/EOEPCA‚Äã/open‚Äã-science‚Äã-catalog‚Äã-metadata‚Äã-staging\n\nGo to /products/ folder to extend the list of products:\n\nOpen any folder with the short product name and check the metadata file stored in collection.json format.\n\nClick on Editing mode and open JSON file with \n\ngithub.dev to make changes or to copy the content of JSON file in web-based editor.\n\nIn GutHub web-based text editor (\n\ngithub.dev), select ‚ÄúSource controller‚Äù and ‚ÄúCreate a new branch‚Äù\n\nSwitch to new Branch:\n\nGo to Explorer and Add a new folder where you can store the collection.json with metadata of your Product. Name your folder with a unique name (id) that you give to your product!\n\n\nCreate collection.json file and add all metadata needed for the product. The simplest way to create a new collection.json is to CTRL+A and CTRL+C of existing collection.json (even from different project and CTRL+V to a new empty collection.json created.\n\nYou can see the file being modified with the capital letter M.\n\nCommit and Push changes from Source Control Panel. Write a purpose or a subject of changes made in the ‚ÄúMessage‚Äù field.\n\nCreate Pull Request to request changes in the repository!\n\nOnce created the Pull Request will be accepted or rejected by open-science-catalog-metadata administrator.","type":"content","url":"/stactools-old-example#add-metadata-of-a-single-product-item-to-the-catalogue","position":5},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Ingest metadata of assets with STAC Catalog"},"type":"lvl2","url":"/stactools-old-example#ingest-metadata-of-assets-with-stac-catalog","position":6},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Ingest metadata of assets with STAC Catalog"},"content":"As mentioned in the previous sub-chapter metadata repository is stored in the GitHub repository. For ingestion of data that are stored in structural catalog, user should convert this file structure to ingest to STAC catalog. Then created STAC collection can be directly imported to GitHub and merged to existing Open Science Data Catalogue repository.\n\nTo convert the file structure to STAC collection, please refer to \n\nstactools documentation, which describes best practices on creation of such collection.\n\nData owners interested in ingestion of multiple products to the catalog are asked to convert their dataset directly into STAC items collection. This especially refers to large datasets (e.g. multitemporal .nc files containing monthly products for a time period of 20 years). Is such case data owners or principal investigators of the project will be provided with script which facilitates that process of ingestions if such products, allowing their conversion to .json STAC items collection.","type":"content","url":"/stactools-old-example#ingest-metadata-of-assets-with-stac-catalog","position":7},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple or single product(s) stored in external server (open-access storage) with STAC Catalogue"},"type":"lvl2","url":"/stactools-old-example#add-multiple-or-single-product-s-stored-in-external-server-open-access-storage-with-stac-catalogue","position":8},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple or single product(s) stored in external server (open-access storage) with STAC Catalogue"},"content":"In the previous section the steps applied described a process to ingest metadata and the access to products stored in external server which may provide open data access to anyone or to registered users in some cases.\n\nIn this scenario complete instructions are provided for how to import larger datasets when multiple changes to the files stored in open science data catalog in GitHub repository are required. With our current system, it is impossible for the user to keep track 10+ open pull requests, so when user requires multiple changes at once, Git with a code editor is recommended.\n\nThe description on how to import STAC catalogue which is preferred method of an ingestion of asset metadata is described in details. This will allow end users to access metadata of individual granules (stored originally in the cloud-native external server) and download them to local storage separately without the need of bulk downloading of all files at once. The workflow includes:\n\nFind the description of the dataset in Open Science Data Catalogue frontend.\nIf the product (dataset) does not exist in the catalog yet, add it to the catalog first! (see subchapter above).\n\nPrepare an upload dataset (assets / granules)\nThis step is a prerequisite that must be met for any data collection to make it publicly available and allow end user to discover and use the data. This can be done in two modes:\na) uploading data to s3 bucket administrated by OSC developers,\nb) provide link to capable HTTP where files are already available to download or / and preview.\n\nIn this case assets are stored in open-access repository:\n\n\nMaddalena et al. (2023).\n\nTherefore, no preliminary steps are required related to data relocation from this source repository.\nThe preparation of the dataset must consist first of assessing the exact full path to original repository for each granule. In this case the list of products is loaded and save in standard text file:curl -sL \"https://zenodo.org/record/7568049#.ZDbG4nbP1aQ\" | grep -oP '<a href=\"\\K([^\"]+\\.tif)' > tiff_links.txt ; sed -i 's|^|https://zenodo.org|' tiff_links.txt\n\nIn case of a long list of files to be converted at once it is advised to split the list of links for each granule into smaller list. It has been confirmed that up to 10 files can be written to JSON format at once using the tool proposed.\n\nCreate STAC Catalog for the dataset\n\na. Create a structure of catalog.json (could only be 1, but depending on the dataset size and structure it can be more)\nb. Create STAC Items data items (granules). Either:\ni. for 2D raster datasets: _ stac create-item _\nii. for netcdfs/ZARRs stac datacube create\niii. other tools?\niv. or manually***\n\nIn this scenario a 2D raster datasets are used and the STAC catalog is created with open-source tool ‚Äòstac create-item‚Äô (i). In case of multiple items to be converted at once, a for loop is created to create stac item .json file for each granule by accessing separate item in a loop:mkdir item_files ; for line in $(cat tiff_links.txt); do item_json=\"item_files/item_$line_number.json\"; echo $line ; stac create-item \"$line\" | tee \"$item_json\"; sleep 3; ((line_number++)); done < \"tiff_links.txt\"\n\n** Note: once files are created, you can access the metadata by opening and reading single item.json file with cat item.json\n\n*** Future updates in the guide are foreseen and guidance specific to most commonly used data formats will be provided. To manually create JSON file, please refer to general file structure provided in the STAC documentation: \n\nexamples‚Äã/core‚Äã-item‚Äã.json.\n\nc. Add STAC Items into Catalog structure\n\nTo create appropriately catalog.json file that lists all related items to specific collection and gathers them in the catalog, it is necessary to follow strict catalog.json file formatting as suggested in:\n\nhttps://github.com/radiantearth/stac-spec/blob/master/examples/catalog.json\n\nPlease download the template on how this catalog.json should looks like and  upload it into the directory where the item files are stored.\n\nMake necessary correction to imported catalog.json example file:\n\nthe only changes which are required is to remove ‚Äúchild‚Äù and ‚Äúitem‚Äù entries from the catalog.json.\n\nItem entries will be updated automatically once you add the assets.\n\nUpdate the default description and title of the catalog\n\nThe final catalog.json should looks like this:\n{\n  \"type\": \"Catalog\",\n  \"id\": \"examples\",\n  \"title\": \"Example catalog\",\n  \"stac_version\": \"1.0.0\",\n  \"description\": \"This catalog is a simple demonstration of an example catalog that is used to organize STAC Items\",\n  \"links\": [\n    {\n      \"rel\": \"self\",\n      \"href\": \"https://raw.githubusercontent.com/radiantearth/stac-spec/v1.1.0/examples/catalog.json\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"rel\": \"root\",\n      \"href\": \"./catalog.json\",\n      \"type\": \"application/json\",\n      \"title\": \"Example catalog\"\n    }\n  ]\n}\n\nNOTE: While working on Linux based environment you can make changes with vi catalog.json in terminal.\n\n**Add STAC Items to a common  _catalog.json _ by applying _ ‚Äòstac add‚Äô _ commandfor item_file in item_files/item_*.json; do stac add \"$item_file\" catalog.json; done;\n\nExport the catalog structure _ stac copy _\n\nBefore performing this step, remember to  change the directory  from the input data collection to output repository which will be copied to s3 bucket!stac copy catalog.json item_10files/out_json/ -l[https://s3.waw2-1.cloudferro.com/swift/v1/AUTH_3f7e5dd853f54cebb046a29a69f1bba6/Catalogs/4DGreenland/supraglacial-storage-and-drainage-lake-features-mapped-by-sentinel1/catalog.json](https://s3.waw2-1.cloudferro.com/swift/v1/AUTH_3f7e5dd853f54cebb046a29a69f1bba6/Catalogs/4DGreenland/supraglacial-storage-and-drainage-lake-features-mapped-by-sentinel1/catalog.json)\n\nNOTE: Check first the location of your product within the Open Science Data Catalog repository!\n\nUpload STAC Catalog to S3 or another HTTP service\n\nWith this simple command all JSON files (single granules) are moved to dedicated OSC s3 bucket metadata repository:\n\ns3cmd sync item_10files/out_json/ s3://Catalogs/4DGreenland/supraglacial-storage-and-drainage-lake-features-mapped-by-sentinel1/\n\nAdd reference to Product‚Äôs metadata and give access to created STAC Catalog\n\nIn OSC Catalogue find target product which needs to be updated with the STAC Item‚Äôs collection. To perform this step 'href‚Äô link must be updated, by inserting the list to catalog.json file stored in s3 repository to Product‚Äôs collection.json file. As shown below:{\n\"rel\": \"child\",\n\"href\": \"https://s3.waw2-1.cloudferro.com/swift/v1/AUTH_3f7e5dd853f54cebb046a29a69f1bba6/Catalogs/4DGreenland/supraglacial-storage-and-drainage-lake-features-mapped-by-sentinel1/catalog.json\",\n\"type\": \"application/json\",\n\"title\": \"Items\"\n}\n\nNOTE: You can make changes using GitHub Desktop or within web-based editor as shown in the section before.\n\nCommit changes and create Pull Request\n\nChanges in Product description will be reviewed by OSC administrator and accepted or rejected by administrator.\n\nPreview uploaded STAC granules collection in the Open Science Data Catalogue frontend:\n\nhttps://opensciencedata.esa.int/products/supraglacial-storage-and-drainage-lake-features-mapped-by-sentinel1/collection","type":"content","url":"/stactools-old-example#add-multiple-or-single-product-s-stored-in-external-server-open-access-storage-with-stac-catalogue","position":9},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple or single product(s) originally stored in local repository with STAC Catalogue"},"type":"lvl2","url":"/stactools-old-example#add-multiple-or-single-product-s-originally-stored-in-local-repository-with-stac-catalogue","position":10},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple or single product(s) originally stored in local repository with STAC Catalogue"},"content":"In this scenario large open-source datacube was investigated and made available to be used by open public. Steps presented in this scenario will allow to first change the location of the dataset to make them accessible to all users and create STAC Catalog filled with metadata from datacube. This will allow end users to access metadata of datacube which is accessible, downloadable and can be visualized or further processed in other locations (e.g. Jupyter Notebooks).\n\nPrepare an upload data (assets / granules)\n\nThis step is a prerequisite that must be met for any data collection to make it publicly available and allow end user to discover and use the data.\nThis can be done in two modes:\n\n1) uploading data to s3 bucket administrated by OSC developers,\n2) provide link to capable HTTP where files are already available to download or / and preview.\n\nIn this case the first mode will be used. Datacube is stored in .zip archive making it impossible to be directly accessed and explored. Therefore, a preliminary step required related to data relocation from source repository: \n\nAlonso et al. (2023)to a dedicated folder in OSCAssets repository in Open Science Data Catalogue S3 storage.\n\nFile relocation requires configured access to dedicated S3 bucket which in this case is granted only to authorized contributors.\n\nOnce configured, downloaded product should be extracted and relocated into designated storage, where it will become accessible for anyone.s3cmd sync SeasFireCube_v3.zarr s3://OSCAssets/seasfire/seasfire-cube/SeasFireCube_v3.zarr\n\nCreate a STAC Catalog for the data\na. Create a structure of catalog.json (could only be 1 if not more is necessary)\nb. Create STAC Items data items (granules). Either:\ni. for 2D raster datasets_: stac create-item_\nii. for netcdfs/ZARRs _ stac datacube create-item _\niii. other tools?\niv. or manually\n\n** Future updates in the guide are foreseen and guidance specific to most commonly used data formats will be provided. To manually create catalog.json please refer to basic file structure provided in the STAC documentation.\n\nIn this scenario a 3D datacube is used and the STAC catalog is created with open-source tool ‚Äòstac datacube create-item‚Äô. This command uses ‚Äòstactools‚Äô extension package which allows to create or extend STAC Items dealing with multi-dimensional data formats and to extract datacube related metadata from these assets. Full documentation and the latest release of the package can be found under the link here: \n\nhttps://‚Äãpypi‚Äã.org‚Äã/project‚Äã/stactools‚Äã-datacube/. Once dataset is placed in designated location, it is possible to create JSON file with the following command:stac datacube create-item s3://OSCAssets/seasfire/seasfire-cube/SeasFireCube_v3.zarr/ item.json '--use-driver ZARR\n\n** Note: once files are created, you can access the metadata by opening and reading single item.json file with cat item.json\n\nNext steps taken to enable product to be discoverable within STAC Catalog are the same as in previous use case (see point 2c - 5) and follow the steps described in this previous section.\n\n** Remember to change the folder name and product folder in s3 bucket to relate to adequate product in OSC**\n\nCommit changes and create Pull Request Preview uploaded STAC Item catalog:\nChanges in Product description will be reviewed by OSC administrator and accepted or rejected by administrator.\n\nPreview uploaded STAC granules collection in the Open Science Data Catalogue frontend:\n\n\nhttps://‚Äãopensciencedata‚Äã.esa‚Äã.int‚Äã/products‚Äã/seasfire‚Äã-cube‚Äã/collection\n\nData can be visualized using Jupyter Notebook and dedicated ‚Äòxarray‚Äô Python package to further work with the datacube on-the-cloud and visualize variables.\n\nFull metadata contained in the .zarr file can also be read directly from the browser under: \n\nhttps://‚Äãs3‚Äã.waw2‚Äã-1‚Äã.cloudferro‚Äã.com‚Äã/swift‚Äã/v1‚Äã/AUTH‚Äã_3f7e5dd853f54cebb046a29a69f1bba6‚Äã/OSCAssets‚Äã/seasfire‚Äã/seasfire‚Äã-cube‚Äã/SeasFireCube‚Äã_v3‚Äã.zarr‚Äã/‚Äã.zmetadata","type":"content","url":"/stactools-old-example#add-multiple-or-single-product-s-originally-stored-in-local-repository-with-stac-catalogue","position":11},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple assets at once with GitHub"},"type":"lvl2","url":"/stactools-old-example#add-multiple-assets-at-once-with-github","position":12},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple assets at once with GitHub"},"content":"Once created the JSON files describing each single asset of larger products collection can be imported to Open Science Data Catalogue repository of metadata at once using GitHub.\n\nFor this, GitHub CLI or gh should be used. GitHub CLI is a command-line interface to GitHub for use in terminal or scripts. It facilitates the process of making changes in open access github repository as the one at open-science-data-catalog-metadata and allows to ingest several files at once. To work with this command-line tool. Please check the installation steps first: \n\ndocs‚Äã/install‚Äã_linux‚Äã.md\n\nTo correctly install gh tool, follow these instructions. Please note that instructions provided here refer to Linux Ubuntu OS, and have not been tested on any other software:\n\nInstall System dependencies:sudo apt update\nsudo apt install -y git python3 python3-pip gdal-bin tree jq parallel curl\n\nInstall ‚Äògh‚Äô tool. In case you encounter any issues please follow instructions from here: \n\ndocs‚Äã/install‚Äã_linux‚Äã.mdtype -p curl \\>/dev/null || (sudo apt update && sudo apt install curl -y)\ncurl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \\\n&& sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \\\n&& echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | sudo tee /etc/apt/sources.list.d/github-cli.list \\> /dev/null \\\n&& sudo apt update \\\n&& sudo apt install gh -y‚Äã\n\nInstall Python dependencies\n\nFollowing dependencies are necessary to make correct conversion of products to be published:\n\nstactools - to manage STAC catalogs\n\nstactools-datacube - to enrich STAC items with datacube metadata\n\nTo install following packages copy and paste following in your terminal:pip install -U stactools stactools-datacube\n\n4.Ingest products to GitHub metadata repository using GitHub CLI# clone the git repository:\ngh repo clone \\<insert-user-here\\>/open-science-catalog-metadata.git\n# enter repository\ncd open-science-catalog-metadata\n# create a new branch to work on\ngit checkout -b \\<branch-name\\>\ncd ..\n# merge the output catalog to the metadata repository\nstac merge --as-child \\\n\\<folder-with-JSON-files/catalog.json \\\n# go to the repo again and commit all new/changed files\ncd open-science-catalog-metadata\ngit add \\<project-name\\>/\\<product-name\\>\ngit commit -m\"Adding woc-l4-se-erastar-h\\_v2.0\"\ngit push --set-upstream origin \\<branch-name\\>\ngh pr create -f\n\nCheck the status of Pull Requests in GitHub:\n\nhttps://‚Äãgithub‚Äã.com‚Äã/EOEPCA‚Äã/open‚Äã-science‚Äã-catalog‚Äã-metadata‚Äã/actions\n\nChanges to the Catalogue content will be reviewed and accepted or rejected by the OSC Administrator.","type":"content","url":"/stactools-old-example#add-multiple-assets-at-once-with-github","position":13},{"hierarchy":{"lvl1":"EarthCODE Examples"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"EarthCODE Examples"},"content":"üëã Welcome to the EarthCODE examples book!\n\nHere you will find guides and examples on how to use the various EarthCODE resources.\n\nIf you are looking to upload data to the Open Science Catalog, check out our \n\nOpen Science Catalog Examples.","type":"content","url":"/","position":1}]}