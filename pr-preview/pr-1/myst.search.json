{"version":"1","records":[{"hierarchy":{"lvl1":"Creating a STAC Item Catalog"},"type":"lvl1","url":"/creating-an-item-catalog","position":0},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog"},"content":"","type":"content","url":"/creating-an-item-catalog","position":1},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Context"},"type":"lvl3","url":"/creating-an-item-catalog#context","position":2},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Context"},"content":"","type":"content","url":"/creating-an-item-catalog#context","position":3},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Purpose","lvl3":"Context"},"type":"lvl4","url":"/creating-an-item-catalog#purpose","position":4},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Purpose","lvl3":"Context"},"content":"The purpose of this tutorial is to learn how to share research outcomes with the wider research community in Open Science Catalog. This can be done by creating STAC Catalogs that\ndescribe a specific dataset you are willing to share.\n\nThis tutorial provides steps necessary to Create STAC Item Catalog in an semi-automated way, using the PySTAC library. By following these steps you will be able to create a self-contained STAC Catalog with individual items in a JSON format. This catalog should be hosted in your own (or institutional) public GitHub repository to ensure it is accessible. (See more on the requirements about this Catalog in the \n\ndocumentation).\n\nIn this example we will upload it to an open-access repository on GitHub. In the next tutorial we will create the actual Open Science Catalog entry, where we will create a full metadata description of our dataset with a link to this Item Catalog.","type":"content","url":"/creating-an-item-catalog#purpose","position":5},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl5":"STAC Items","lvl4":"Purpose","lvl3":"Context"},"type":"lvl5","url":"/creating-an-item-catalog#stac-items","position":6},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl5":"STAC Items","lvl4":"Purpose","lvl3":"Context"},"content":"A STAC Item is the lowest level component of a STAC catalog. All STAC Items must have an associated data Asset, in addition to the Asset (which you can think of as a data file), the Item also contains metadata about the data itself, such as:\n\nSpatioTemporal extent including start and end time and geographical extent (coordinates)\n\nVariables\n\nFile type\n\nFile size\n\nImportant\n\nThink about the persistence of your data!\nIf your data files are not currently stored in an open-access and persistent storage, you can \n\ncontact the ESA team who will assist you to upload your data to the ESA Project Results Repository (PRR). The same applies for the repository we will upload our STAC Item Catalog to!","type":"content","url":"/creating-an-item-catalog#stac-items","position":7},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Prerequisites","lvl3":"Context"},"type":"lvl4","url":"/creating-an-item-catalog#prerequisites","position":8},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Prerequisites","lvl3":"Context"},"content":"In this example we assume that the data files are already uploaded to a remote storage, and we have access to the download URLs, but feel free to modify this example for your own data files!\n\nWe will be using this supraglacial lakes dataset: \n\nhttps://​zenodo​.org​/records​/7568049​#​.ZDbG4nbP1aQ. We have also noted down the download links for 5 of the assets:https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20171111T205337_20171111T205438_008239_00E91A_F8D1.tif\nhttps://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20190224T203744_20190224T203844_015093_01C356_B9C1.tif\nhttps://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20170620T205332_20170620T205433_006139_00AC89_6857.tif\nhttps://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20180923T202118_20180923T202218_012847_017B82_7DD5.tif\nhttps://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20181108T203747_20181108T203847_013518_01903B_D463.tif\n\nThis notebook uses Python 3.10.11\n\nTip\n\nYou can reuse this example with your own data links, as long as they point to an open access, persistent and remote storage!\n\n","type":"content","url":"/creating-an-item-catalog#prerequisites","position":9},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Loading Libraries"},"type":"lvl3","url":"/creating-an-item-catalog#loading-libraries","position":10},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Loading Libraries"},"content":"Make sure you have installed the requirements, e.g. with pip install pystac rasterio\n\nimport json\nimport time\nimport requests\n\nimport pystac\nimport rasterio\nfrom pathlib import Path\n\n","type":"content","url":"/creating-an-item-catalog#loading-libraries","position":11},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl2":"Creating the Item Catalog"},"type":"lvl2","url":"/creating-an-item-catalog#creating-the-item-catalog","position":12},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl2":"Creating the Item Catalog"},"content":"To correctly reference our Items, they need to be linked in the STAC Catalog. This catalog should also include the following minimum information:\n\nTitle of the Catalog\n\nDescription\n\nID (e.g. catalog-id: can be short name of the dataset)\n\ntitle = \"Item Catalog Example\"\ndescription = \"A collection of supraglacial lakes data in a very useful example notebook.\"\ncatalog_id = \"supraglacial-lakes-example-2025\"\n\ncatalog = pystac.Catalog(\n    id=catalog_id,\n    title=title,\n    description=description,\n)\n\ncatalog\n\nThat’s all! Most of the metadata will be added to the Items which we will add to this catalog shortly.\n\n","type":"content","url":"/creating-an-item-catalog#creating-the-item-catalog","position":13},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Creating a single STAC Item","lvl2":"Creating the Item Catalog"},"type":"lvl3","url":"/creating-an-item-catalog#creating-a-single-stac-item","position":14},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Creating a single STAC Item","lvl2":"Creating the Item Catalog"},"content":"Manually creating STAC Items can be cumbersome and is prone to errors (but possible!). Luckily there are many tools that can make the process a lot easier.\n\nHere we will use rio_stac \n\n(documentation here) which is a library that we can use to open and extract metadata from raster datasets.\n\nfilenames = [\n    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20171111T205337_20171111T205438_008239_00E91A_F8D1.tif\",\n    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20190224T203744_20190224T203844_015093_01C356_B9C1.tif\",\n    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20170620T205332_20170620T205433_006139_00AC89_6857.tif\",\n    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20180923T202118_20180923T202218_012847_017B82_7DD5.tif\",\n    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20181108T203747_20181108T203847_013518_01903B_D463.tif\",\n]\n\nfrom rio_stac import create_stac_item\n\nitem = create_stac_item(\n    source=filenames[0],\n    id=\"item_1\",\n    asset_name=\"data\",  # EarthCODE standard asset name\n    # all the metadata!\n    with_eo=True,\n    with_proj=True,\n    with_raster=True,\n)\n\nInspecting the result we can see that this function has extracted rich information about our raster file. This information is attached to the Item. This Item also has an \"assets\" attribute which references the actual data.\n\nImportant: Verify that your references always point to the remote open storage!\n\nitem\n\n","type":"content","url":"/creating-an-item-catalog#creating-a-single-stac-item","position":15},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Creating the rest of our Items","lvl2":"Creating the Item Catalog"},"type":"lvl3","url":"/creating-an-item-catalog#creating-the-rest-of-our-items","position":16},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Creating the rest of our Items","lvl2":"Creating the Item Catalog"},"content":"Now that we have shown how to generate a single Item using rio_stac, we can repeat the process for the rest of our data files. The goal is to create a list of STAC Items, that we can add to our Catalog with the buit-in Catalog.add_items() method.\n\nWe could in principle just iterate over the method above, but in order to respect the rate limits for our data provider (Zenodo), we define a function which reads the response headers and responds appropriately.\n\nThis function also saves the file to a local temporary destination instead of reading the data from Zenodo directly.\n\nimport time\nimport requests\n\ndef download_zenodo_file(url: str, local_path: str, max_retries: int = 5) -> None:\n    \"\"\"\n    Download a file from Zenodo into local_path, respecting rate limits if we hit 429 responses.\n    \n    :param url: The direct download URL from Zenodo.\n    :param local_path: Where to save the file locally.\n    :param max_retries: Number of times to retry the download if repeatedly rate-limited.\n    \"\"\"\n    attempt = 0\n    \n    while attempt < max_retries:\n        response = requests.get(url, stream=True)\n        \n        if response.status_code == 200:\n            with open(local_path, 'wb') as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    f.write(chunk)\n            return \n        \n        # If rate-limited (HTTP 429), then check rate-limit headers and wait.\n        elif response.status_code == 429:\n            attempt += 1\n            if reset_timestamp := response.headers.get(\"X-RateLimit-Reset\") is not None:\n                now = time.time()\n                wait_seconds = int(reset_timestamp) - int(now)\n                wait_seconds = max(wait_seconds, 1)  # Wait at least 1 second.\n                print(f\"Got 429 Too Many Requests. Waiting ~{wait_seconds} seconds.\")\n                time.sleep(wait_seconds)\n        else:\n            response.raise_for_status()\n    \n    raise RuntimeError(f\"Failed to download {url} after {max_retries} retries.\")\n\nNow we can iterate over the rest of our data files and create the STAC items.\n\nimport rasterio\n\nitems = []\nlocal_tmp_file = \"tmp.tif\"\n\nfor idx, remote_url in enumerate(filenames[0:]):\n    # Save our dataset to the temporary file\n    download_zenodo_file(remote_url, local_tmp_file)\n\n    # Inspect the local file and create a STAC Item\n    item = create_stac_item(\n        source=local_tmp_file,\n        id=f\"item_{idx+1}\",\n        asset_name=\"data\",\n        asset_href=remote_url,  # Explicitly set the asset reference to the remote one!\n        with_eo=True,\n        with_proj=True,\n        with_raster=True,\n    )\n\n    items.append(item)\n\n# Verify that our items all point to the correct reference\nfor item in items:\n    print(item.assets['data'].href)\n\nLooks good!\n\n","type":"content","url":"/creating-an-item-catalog#creating-the-rest-of-our-items","position":17},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Adding Items to our Item Catalog","lvl2":"Creating the Item Catalog"},"type":"lvl3","url":"/creating-an-item-catalog#adding-items-to-our-item-catalog","position":18},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Adding Items to our Item Catalog","lvl2":"Creating the Item Catalog"},"content":"Now that we have defined our items, we can add them to our catalog.\n\ncatalog.add_items(items)\n\ncatalog\n\n","type":"content","url":"/creating-an-item-catalog#adding-items-to-our-item-catalog","position":19},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Saving the Catalog","lvl2":"Creating the Item Catalog"},"type":"lvl3","url":"/creating-an-item-catalog#saving-the-catalog","position":20},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Saving the Catalog","lvl2":"Creating the Item Catalog"},"content":"If we inspect the Catalog, we can see that it now contains Links to the Items, but the links themselves don’t contain any references.\n\nWith PySTAC, the real magic happens when you normalize and save the Catalog. This is when all the links are resolved, and a folder structure will be laid out following best practices, automatically!\n\nWhat we will do is to specify a target location, which will become the root folder of our Catalog. When we normalize the Catalog to this folder, all the internal references will be resolved with relative paths. When we save the Catalog, PySTAC will generate the JSON files in the folder we just normalized to.\n\nWe normalize and save the Catalog as “self contained”. Here is the description of a self-contained catalog from the \n\nPySTAC API documentation:\n\n“A ‘self-contained catalog’ is one that is designed for portability. Users may want to download an online catalog from and be able to use it on their local computer, so all links need to be relative.”\n\nIn other words, exactly what we want to make our data accessible!\n\noutput_folder = \"supraglacial-lakes-item-catalog\"\n\ncatalog.normalize_and_save(root_href=output_folder, catalog_type=pystac.CatalogType.SELF_CONTAINED)\n\nIf you inspect the Catalog you can see that PySTAC has added a few more links to our Catalog, namely to the root catalog and itself, which in this istance is the same.\n\nAlso notice that the Link.href attributes show absolute paths in the notebook. However, you should now have the actual STAC catalog saved in the output_folder.\n\nThe folder will have the following structure:supraglacial-lakes-item-catalog\n├── catalog.json\n├── item_1\n│   └── item_1.json\n├── item_2\n│   └── item_2.json\n├── item_3\n│   └── item_3.json\n├── item_4\n│   └── item_4.json\n└── item_5\n    └── item_5.json\n\nLooking at the catalog.json:{\n  \"type\": \"Catalog\",\n  \"id\": \"supraglacial-lakes-example-2025\",\n  \"stac_version\": \"1.1.0\",\n  \"description\": \"A collection of supraglacial lakes data in a very useful example notebook.\",\n  \"links\": [\n    {\n      \"rel\": \"root\",\n      \"href\": \"./catalog.json\",\n      \"type\": \"application/json\",\n      \"title\": \"Item Catalog Example\"\n    },\n    {\n      \"rel\": \"item\",\n      \"href\": \"./item_1/item_1.json\",\n      \"type\": \"application/geo+json\"\n    },\n    {\n      \"rel\": \"item\",\n      \"href\": \"./item_2/item_2.json\",\n      \"type\": \"application/geo+json\"\n    },\n    {\n      \"rel\": \"item\",\n      \"href\": \"./item_3/item_3.json\",\n      \"type\": \"application/geo+json\"\n    },\n    {\n      \"rel\": \"item\",\n      \"href\": \"./item_4/item_4.json\",\n      \"type\": \"application/geo+json\"\n    },\n    {\n      \"rel\": \"item\",\n      \"href\": \"./item_5/item_5.json\",\n      \"type\": \"application/geo+json\"\n    }\n  ],\n  \"title\": \"Item Catalog Example\"\n}\n\nwe can verify that everything looks correct.\n\nThe item JSON files should have the following links:  \"links\": [\n    {\n      \"rel\": \"root\",\n      \"href\": \"../catalog.json\",\n      \"type\": \"application/json\",\n      \"title\": \"Item Catalog Example\"\n    },\n    {\n      \"rel\": \"parent\",\n      \"href\": \"../catalog.json\",\n      \"type\": \"application/json\",\n      \"title\": \"Item Catalog Example\"\n    }\n  ],\n\n... among all the other metadata we have added.\n\nThat's it! We have now created a self-contained STAC Item Catalog that contains all the metadata of our data, in compliance with the EarthCODE specifications for FAIR and open science. Now we just need to upload it to somewhere people can access it.\n\n","type":"content","url":"/creating-an-item-catalog#saving-the-catalog","position":21},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Upload the Item Catalog","lvl2":"Creating the Item Catalog"},"type":"lvl3","url":"/creating-an-item-catalog#upload-the-item-catalog","position":22},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl3":"Upload the Item Catalog","lvl2":"Creating the Item Catalog"},"content":"In this part we will upload the Catalog in order to make it available. Feel free to do this in any way you like as long as you are sure the files will remain accessible!\n\nA good option is to upload the files we just created to GitHub. In the next part of the tutorial, when we will create an entry to the Open Science Catalog, we will only need the URL for the catalog.json we have in our root. The STAC browser will read the files directly from this repository and extract all the information from our Items automatically.\n\nWe will now show how this can be done with GitHub and the git CLI.\n\n","type":"content","url":"/creating-an-item-catalog#upload-the-item-catalog","position":23},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Create a public GitHub repository","lvl3":"Upload the Item Catalog","lvl2":"Creating the Item Catalog"},"type":"lvl4","url":"/creating-an-item-catalog#create-a-public-github-repository","position":24},{"hierarchy":{"lvl1":"Creating a STAC Item Catalog","lvl4":"Create a public GitHub repository","lvl3":"Upload the Item Catalog","lvl2":"Creating the Item Catalog"},"content":"Go to \n\ngithub.com/new and create a remote repository. Here we will name it the same as our local folder, make sure it is set to public, and ignore everything else.\n\n\n\nGitHub create a new repository\n\nAfter creating the repository, you can simply click upload existing files to upload your files manually, or if you are comfortable with git, do it through the command line interface:# Navigate to the Item Catalog we want to upload\ncd supraglacial-lakes-item-catalog\n\n# Initialise it as a git repository\ngit init\n\n# Add the URL to your newly created GitHub repository as the remote version of your local files\ngit remote add origin https://github.com/<username>/supraglacial-lakes-item-catalog.git\n\n# Add and commit your files\ngit add --all\ngit commit -m \"Useful commit message\"\n\n# Set the remote main as the upstream version of your local main, and push your changes\ngit push --set-upstream origin main\n\nWhen you refresh GitHub page, you should see your STAC catalog.\n\n\n\nNew GitHub repository\n\nThat’s it!\n\nIn the next stages we will explain how to create and add your product to the Open Science Catalog, linking to the Items we just created.","type":"content","url":"/creating-an-item-catalog#create-a-public-github-repository","position":25},{"hierarchy":{"lvl1":"DeepCode"},"type":"lvl1","url":"/deepcode-example","position":0},{"hierarchy":{"lvl1":"DeepCode"},"content":"A tutorial on how to use DeepCode to upload data to the Open Science Catalog.","type":"content","url":"/deepcode-example","position":1},{"hierarchy":{"lvl1":"Git Clerk"},"type":"lvl1","url":"/git-clerk-example","position":0},{"hierarchy":{"lvl1":"Git Clerk"},"content":"A tutorial on how to use the Git Clerk to upload data to the Open Science Catalog.","type":"content","url":"/git-clerk-example","position":1},{"hierarchy":{"lvl1":"Open Science Catalog"},"type":"lvl1","url":"/index-1","position":0},{"hierarchy":{"lvl1":"Open Science Catalog"},"content":"","type":"content","url":"/index-1","position":1},{"hierarchy":{"lvl1":"Open Science Catalog","lvl2":"Uploading data to the Open Science Catalog"},"type":"lvl2","url":"/index-1#uploading-data-to-the-open-science-catalog","position":2},{"hierarchy":{"lvl1":"Open Science Catalog","lvl2":"Uploading data to the Open Science Catalog"},"content":"Here you can find guides and example notebooks on how to use the Open Science Catalog.","type":"content","url":"/index-1#uploading-data-to-the-open-science-catalog","position":3},{"hierarchy":{"lvl1":"Open Science Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"type":"lvl3","url":"/index-1#uploading-data","position":4},{"hierarchy":{"lvl1":"Open Science Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"content":"If you are looking to upload your data please refer to the following guides. Choose the method that best suits your use case!","type":"content","url":"/index-1#uploading-data","position":5},{"hierarchy":{"lvl1":"Open Science Catalog","lvl4":"1: Creating and Uploading an Item Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"type":"lvl4","url":"/index-1#id-1-creating-and-uploading-an-item-catalog","position":6},{"hierarchy":{"lvl1":"Open Science Catalog","lvl4":"1: Creating and Uploading an Item Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"content":"Creating an Item Catalog - A notebook explaining how Item Catalogs should be created, uses raster data.","type":"content","url":"/index-1#id-1-creating-and-uploading-an-item-catalog","position":7},{"hierarchy":{"lvl1":"Open Science Catalog","lvl4":"2: Adding a Product entry to the Open Science Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"type":"lvl4","url":"/index-1#id-2-adding-a-product-entry-to-the-open-science-catalog","position":8},{"hierarchy":{"lvl1":"Open Science Catalog","lvl4":"2: Adding a Product entry to the Open Science Catalog","lvl3":"Uploading Data","lvl2":"Uploading data to the Open Science Catalog"},"content":"PySTAC notebook - A guide for manually creating Product entries using PySTAC. Requires some knowledge of git.\n\nGit Clerk - A guide for using the Git Clerk tool which is a user interface for automatically creating product entries and creating a Pull Request in the OSC GitHub Repo.\n\nDeepCode - An example using DeepCode: a library for automatically generating product entries for DeepESDL datasets.","type":"content","url":"/index-1#id-2-adding-a-product-entry-to-the-open-science-catalog","position":9},{"hierarchy":{"lvl1":"Manual Example (PySTAC)"},"type":"lvl1","url":"/manual-example","position":0},{"hierarchy":{"lvl1":"Manual Example (PySTAC)"},"content":"A tutorial on how to manually (and painstakingly) add a product to the OSC.","type":"content","url":"/manual-example","position":1},{"hierarchy":{"lvl1":"Stactools Full Example"},"type":"lvl1","url":"/stactools-old-example","position":0},{"hierarchy":{"lvl1":"Stactools Full Example"},"content":"","type":"content","url":"/stactools-old-example","position":1},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"System requirements"},"type":"lvl2","url":"/stactools-old-example#system-requirements","position":2},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"System requirements"},"content":"Ubuntu OS min version > 20. Script tested on Ubuntu 22.04 and Ubuntu 20.04 version.\n\nMinimum requirements: 2 GB RAM, 2 CPUs, 32 GB of disk space.\n\nUser with full sudo privileges to run all Linux commands and install packages as root.\n\nSelection of packages to be installed in order to run bash script: python 3 , gdal , tree, jq, parallel , curl, stactools.\n\nPython 3.8 or greater\n\nFollowing dependencies are necessary to make correct conversion of products to be published: stactools - to manage STAC catalogs\nstactools-datacube - to enrich STAC items with datacube metadata\nPlease find full documentation and installation instructions here: \n\nhttps://​stactools​.readthedocs​.io​/en​/stable​/index​.html","type":"content","url":"/stactools-old-example#system-requirements","position":3},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add metadata of a single product (item) to the catalogue"},"type":"lvl2","url":"/stactools-old-example#add-metadata-of-a-single-product-item-to-the-catalogue","position":4},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add metadata of a single product (item) to the catalogue"},"content":"Manual ingestion of single item into catalogue is rather simple and straightforward when you have all metadata prepared correctly and when you follow these few steps on how to add new product (collection.json) to a publicly open repository of Open Science Data Catalogue.\n\nPlease note that this workflow is applicable also to other elements of the catalogue such as Projects, Themes, Variables, EO Missions.\nHere the procedure of adding or updating metadata of single item using GitHub on Web browser is provided.\n\nGo to open-science-catalog-metadata-staging repository:\n\n\nhttps://​github​.com​/EOEPCA​/open​-science​-catalog​-metadata​-staging\n\nGo to /products/ folder to extend the list of products:\n\nOpen any folder with the short product name and check the metadata file stored in collection.json format.\n\nClick on Editing mode and open JSON file with \n\ngithub.dev to make changes or to copy the content of JSON file in web-based editor.\n\nIn GutHub web-based text editor (\n\ngithub.dev), select “Source controller” and “Create a new branch”\n\nSwitch to new Branch:\n\nGo to Explorer and Add a new folder where you can store the collection.json with metadata of your Product. Name your folder with a unique name (id) that you give to your product!\n\n\nCreate collection.json file and add all metadata needed for the product. The simplest way to create a new collection.json is to CTRL+A and CTRL+C of existing collection.json (even from different project and CTRL+V to a new empty collection.json created.\n\nYou can see the file being modified with the capital letter M.\n\nCommit and Push changes from Source Control Panel. Write a purpose or a subject of changes made in the “Message” field.\n\nCreate Pull Request to request changes in the repository!\n\nOnce created the Pull Request will be accepted or rejected by open-science-catalog-metadata administrator.","type":"content","url":"/stactools-old-example#add-metadata-of-a-single-product-item-to-the-catalogue","position":5},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Ingest metadata of assets with STAC Catalog"},"type":"lvl2","url":"/stactools-old-example#ingest-metadata-of-assets-with-stac-catalog","position":6},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Ingest metadata of assets with STAC Catalog"},"content":"As mentioned in the previous sub-chapter metadata repository is stored in the GitHub repository. For ingestion of data that are stored in structural catalog, user should convert this file structure to ingest to STAC catalog. Then created STAC collection can be directly imported to GitHub and merged to existing Open Science Data Catalogue repository.\n\nTo convert the file structure to STAC collection, please refer to \n\nstactools documentation, which describes best practices on creation of such collection.\n\nData owners interested in ingestion of multiple products to the catalog are asked to convert their dataset directly into STAC items collection. This especially refers to large datasets (e.g. multitemporal .nc files containing monthly products for a time period of 20 years). Is such case data owners or principal investigators of the project will be provided with script which facilitates that process of ingestions if such products, allowing their conversion to .json STAC items collection.","type":"content","url":"/stactools-old-example#ingest-metadata-of-assets-with-stac-catalog","position":7},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple or single product(s) stored in external server (open-access storage) with STAC Catalogue"},"type":"lvl2","url":"/stactools-old-example#add-multiple-or-single-product-s-stored-in-external-server-open-access-storage-with-stac-catalogue","position":8},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple or single product(s) stored in external server (open-access storage) with STAC Catalogue"},"content":"In the previous section the steps applied described a process to ingest metadata and the access to products stored in external server which may provide open data access to anyone or to registered users in some cases.\n\nIn this scenario complete instructions are provided for how to import larger datasets when multiple changes to the files stored in open science data catalog in GitHub repository are required. With our current system, it is impossible for the user to keep track 10+ open pull requests, so when user requires multiple changes at once, Git with a code editor is recommended.\n\nThe description on how to import STAC catalogue which is preferred method of an ingestion of asset metadata is described in details. This will allow end users to access metadata of individual granules (stored originally in the cloud-native external server) and download them to local storage separately without the need of bulk downloading of all files at once. The workflow includes:\n\nFind the description of the dataset in Open Science Data Catalogue frontend.\nIf the product (dataset) does not exist in the catalog yet, add it to the catalog first! (see subchapter above).\n\nPrepare an upload dataset (assets / granules)\nThis step is a prerequisite that must be met for any data collection to make it publicly available and allow end user to discover and use the data. This can be done in two modes:\na) uploading data to s3 bucket administrated by OSC developers,\nb) provide link to capable HTTP where files are already available to download or / and preview.\n\nIn this case assets are stored in open-access repository:\n\n\nMaddalena et al. (2023).\n\nTherefore, no preliminary steps are required related to data relocation from this source repository.\nThe preparation of the dataset must consist first of assessing the exact full path to original repository for each granule. In this case the list of products is loaded and save in standard text file:curl -sL \"https://zenodo.org/record/7568049#.ZDbG4nbP1aQ\" | grep -oP '<a href=\"\\K([^\"]+\\.tif)' > tiff_links.txt ; sed -i 's|^|https://zenodo.org|' tiff_links.txt\n\nIn case of a long list of files to be converted at once it is advised to split the list of links for each granule into smaller list. It has been confirmed that up to 10 files can be written to JSON format at once using the tool proposed.\n\nCreate STAC Catalog for the dataset\n\na. Create a structure of catalog.json (could only be 1, but depending on the dataset size and structure it can be more)\nb. Create STAC Items data items (granules). Either:\ni. for 2D raster datasets: _ stac create-item _\nii. for netcdfs/ZARRs stac datacube create\niii. other tools?\niv. or manually***\n\nIn this scenario a 2D raster datasets are used and the STAC catalog is created with open-source tool ‘stac create-item’ (i). In case of multiple items to be converted at once, a for loop is created to create stac item .json file for each granule by accessing separate item in a loop:mkdir item_files ; for line in $(cat tiff_links.txt); do item_json=\"item_files/item_$line_number.json\"; echo $line ; stac create-item \"$line\" | tee \"$item_json\"; sleep 3; ((line_number++)); done < \"tiff_links.txt\"\n\n** Note: once files are created, you can access the metadata by opening and reading single item.json file with cat item.json\n\n*** Future updates in the guide are foreseen and guidance specific to most commonly used data formats will be provided. To manually create JSON file, please refer to general file structure provided in the STAC documentation: \n\nexamples​/core​-item​.json.\n\nc. Add STAC Items into Catalog structure\n\nTo create appropriately catalog.json file that lists all related items to specific collection and gathers them in the catalog, it is necessary to follow strict catalog.json file formatting as suggested in:\n\nhttps://github.com/radiantearth/stac-spec/blob/master/examples/catalog.json\n\nPlease download the template on how this catalog.json should looks like and  upload it into the directory where the item files are stored.\n\nMake necessary correction to imported catalog.json example file:\n\nthe only changes which are required is to remove “child” and “item” entries from the catalog.json.\n\nItem entries will be updated automatically once you add the assets.\n\nUpdate the default description and title of the catalog\n\nThe final catalog.json should looks like this:\n{\n  \"type\": \"Catalog\",\n  \"id\": \"examples\",\n  \"title\": \"Example catalog\",\n  \"stac_version\": \"1.0.0\",\n  \"description\": \"This catalog is a simple demonstration of an example catalog that is used to organize STAC Items\",\n  \"links\": [\n    {\n      \"rel\": \"self\",\n      \"href\": \"https://raw.githubusercontent.com/radiantearth/stac-spec/v1.1.0/examples/catalog.json\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"rel\": \"root\",\n      \"href\": \"./catalog.json\",\n      \"type\": \"application/json\",\n      \"title\": \"Example catalog\"\n    }\n  ]\n}\n\nNOTE: While working on Linux based environment you can make changes with vi catalog.json in terminal.\n\n**Add STAC Items to a common  _catalog.json _ by applying _ ‘stac add’ _ commandfor item_file in item_files/item_*.json; do stac add \"$item_file\" catalog.json; done;\n\nExport the catalog structure _ stac copy _\n\nBefore performing this step, remember to  change the directory  from the input data collection to output repository which will be copied to s3 bucket!stac copy catalog.json item_10files/out_json/ -l[https://s3.waw2-1.cloudferro.com/swift/v1/AUTH_3f7e5dd853f54cebb046a29a69f1bba6/Catalogs/4DGreenland/supraglacial-storage-and-drainage-lake-features-mapped-by-sentinel1/catalog.json](https://s3.waw2-1.cloudferro.com/swift/v1/AUTH_3f7e5dd853f54cebb046a29a69f1bba6/Catalogs/4DGreenland/supraglacial-storage-and-drainage-lake-features-mapped-by-sentinel1/catalog.json)\n\nNOTE: Check first the location of your product within the Open Science Data Catalog repository!\n\nUpload STAC Catalog to S3 or another HTTP service\n\nWith this simple command all JSON files (single granules) are moved to dedicated OSC s3 bucket metadata repository:\n\ns3cmd sync item_10files/out_json/ s3://Catalogs/4DGreenland/supraglacial-storage-and-drainage-lake-features-mapped-by-sentinel1/\n\nAdd reference to Product’s metadata and give access to created STAC Catalog\n\nIn OSC Catalogue find target product which needs to be updated with the STAC Item’s collection. To perform this step 'href’ link must be updated, by inserting the list to catalog.json file stored in s3 repository to Product’s collection.json file. As shown below:{\n\"rel\": \"child\",\n\"href\": \"https://s3.waw2-1.cloudferro.com/swift/v1/AUTH_3f7e5dd853f54cebb046a29a69f1bba6/Catalogs/4DGreenland/supraglacial-storage-and-drainage-lake-features-mapped-by-sentinel1/catalog.json\",\n\"type\": \"application/json\",\n\"title\": \"Items\"\n}\n\nNOTE: You can make changes using GitHub Desktop or within web-based editor as shown in the section before.\n\nCommit changes and create Pull Request\n\nChanges in Product description will be reviewed by OSC administrator and accepted or rejected by administrator.\n\nPreview uploaded STAC granules collection in the Open Science Data Catalogue frontend:\n\nhttps://opensciencedata.esa.int/products/supraglacial-storage-and-drainage-lake-features-mapped-by-sentinel1/collection","type":"content","url":"/stactools-old-example#add-multiple-or-single-product-s-stored-in-external-server-open-access-storage-with-stac-catalogue","position":9},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple or single product(s) originally stored in local repository with STAC Catalogue"},"type":"lvl2","url":"/stactools-old-example#add-multiple-or-single-product-s-originally-stored-in-local-repository-with-stac-catalogue","position":10},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple or single product(s) originally stored in local repository with STAC Catalogue"},"content":"In this scenario large open-source datacube was investigated and made available to be used by open public. Steps presented in this scenario will allow to first change the location of the dataset to make them accessible to all users and create STAC Catalog filled with metadata from datacube. This will allow end users to access metadata of datacube which is accessible, downloadable and can be visualized or further processed in other locations (e.g. Jupyter Notebooks).\n\nPrepare an upload data (assets / granules)\n\nThis step is a prerequisite that must be met for any data collection to make it publicly available and allow end user to discover and use the data.\nThis can be done in two modes:\n\n1) uploading data to s3 bucket administrated by OSC developers,\n2) provide link to capable HTTP where files are already available to download or / and preview.\n\nIn this case the first mode will be used. Datacube is stored in .zip archive making it impossible to be directly accessed and explored. Therefore, a preliminary step required related to data relocation from source repository: \n\nAlonso et al. (2023)to a dedicated folder in OSCAssets repository in Open Science Data Catalogue S3 storage.\n\nFile relocation requires configured access to dedicated S3 bucket which in this case is granted only to authorized contributors.\n\nOnce configured, downloaded product should be extracted and relocated into designated storage, where it will become accessible for anyone.s3cmd sync SeasFireCube_v3.zarr s3://OSCAssets/seasfire/seasfire-cube/SeasFireCube_v3.zarr\n\nCreate a STAC Catalog for the data\na. Create a structure of catalog.json (could only be 1 if not more is necessary)\nb. Create STAC Items data items (granules). Either:\ni. for 2D raster datasets_: stac create-item_\nii. for netcdfs/ZARRs _ stac datacube create-item _\niii. other tools?\niv. or manually\n\n** Future updates in the guide are foreseen and guidance specific to most commonly used data formats will be provided. To manually create catalog.json please refer to basic file structure provided in the STAC documentation.\n\nIn this scenario a 3D datacube is used and the STAC catalog is created with open-source tool ‘stac datacube create-item’. This command uses ‘stactools’ extension package which allows to create or extend STAC Items dealing with multi-dimensional data formats and to extract datacube related metadata from these assets. Full documentation and the latest release of the package can be found under the link here: \n\nhttps://​pypi​.org​/project​/stactools​-datacube/. Once dataset is placed in designated location, it is possible to create JSON file with the following command:stac datacube create-item s3://OSCAssets/seasfire/seasfire-cube/SeasFireCube_v3.zarr/ item.json '--use-driver ZARR\n\n** Note: once files are created, you can access the metadata by opening and reading single item.json file with cat item.json\n\nNext steps taken to enable product to be discoverable within STAC Catalog are the same as in previous use case (see point 2c - 5) and follow the steps described in this previous section.\n\n** Remember to change the folder name and product folder in s3 bucket to relate to adequate product in OSC**\n\nCommit changes and create Pull Request Preview uploaded STAC Item catalog:\nChanges in Product description will be reviewed by OSC administrator and accepted or rejected by administrator.\n\nPreview uploaded STAC granules collection in the Open Science Data Catalogue frontend:\n\n\nhttps://​opensciencedata​.esa​.int​/products​/seasfire​-cube​/collection\n\nData can be visualized using Jupyter Notebook and dedicated ‘xarray’ Python package to further work with the datacube on-the-cloud and visualize variables.\n\nFull metadata contained in the .zarr file can also be read directly from the browser under: \n\nhttps://​s3​.waw2​-1​.cloudferro​.com​/swift​/v1​/AUTH​_3f7e5dd853f54cebb046a29a69f1bba6​/OSCAssets​/seasfire​/seasfire​-cube​/SeasFireCube​_v3​.zarr​/​.zmetadata","type":"content","url":"/stactools-old-example#add-multiple-or-single-product-s-originally-stored-in-local-repository-with-stac-catalogue","position":11},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple assets at once with GitHub"},"type":"lvl2","url":"/stactools-old-example#add-multiple-assets-at-once-with-github","position":12},{"hierarchy":{"lvl1":"Stactools Full Example","lvl2":"Add multiple assets at once with GitHub"},"content":"Once created the JSON files describing each single asset of larger products collection can be imported to Open Science Data Catalogue repository of metadata at once using GitHub.\n\nFor this, GitHub CLI or gh should be used. GitHub CLI is a command-line interface to GitHub for use in terminal or scripts. It facilitates the process of making changes in open access github repository as the one at open-science-data-catalog-metadata and allows to ingest several files at once. To work with this command-line tool. Please check the installation steps first: \n\ndocs​/install​_linux​.md\n\nTo correctly install gh tool, follow these instructions. Please note that instructions provided here refer to Linux Ubuntu OS, and have not been tested on any other software:\n\nInstall System dependencies:sudo apt update\nsudo apt install -y git python3 python3-pip gdal-bin tree jq parallel curl\n\nInstall ‘gh’ tool. In case you encounter any issues please follow instructions from here: \n\ndocs​/install​_linux​.mdtype -p curl \\>/dev/null || (sudo apt update && sudo apt install curl -y)\ncurl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \\\n&& sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \\\n&& echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | sudo tee /etc/apt/sources.list.d/github-cli.list \\> /dev/null \\\n&& sudo apt update \\\n&& sudo apt install gh -y​\n\nInstall Python dependencies\n\nFollowing dependencies are necessary to make correct conversion of products to be published:\n\nstactools - to manage STAC catalogs\n\nstactools-datacube - to enrich STAC items with datacube metadata\n\nTo install following packages copy and paste following in your terminal:pip install -U stactools stactools-datacube\n\n4.Ingest products to GitHub metadata repository using GitHub CLI# clone the git repository:\ngh repo clone \\<insert-user-here\\>/open-science-catalog-metadata.git\n# enter repository\ncd open-science-catalog-metadata\n# create a new branch to work on\ngit checkout -b \\<branch-name\\>\ncd ..\n# merge the output catalog to the metadata repository\nstac merge --as-child \\\n\\<folder-with-JSON-files/catalog.json \\\n# go to the repo again and commit all new/changed files\ncd open-science-catalog-metadata\ngit add \\<project-name\\>/\\<product-name\\>\ngit commit -m\"Adding woc-l4-se-erastar-h\\_v2.0\"\ngit push --set-upstream origin \\<branch-name\\>\ngh pr create -f\n\nCheck the status of Pull Requests in GitHub:\n\nhttps://​github​.com​/EOEPCA​/open​-science​-catalog​-metadata​/actions\n\nChanges to the Catalogue content will be reviewed and accepted or rejected by the OSC Administrator.","type":"content","url":"/stactools-old-example#add-multiple-assets-at-once-with-github","position":13},{"hierarchy":{"lvl1":"EarthCODE Examples"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"EarthCODE Examples"},"content":"👋 Welcome to the EarthCODE examples book!\n\nHere you will find guides and examples on how to use the various EarthCODE resources.\n\nIf you are looking to upload data to the Open Science Catalog, check out our \n\nOpen Science Catalog Examples.","type":"content","url":"/","position":1}]}